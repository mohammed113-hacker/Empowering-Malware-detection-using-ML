
import streamlit as st
import os
import tempfile
import joblib
import pickle
import subprocess


def sanitization(web):
    web = web.lower()
    token = []
    dot_token_slash = []
    raw_slash = str(web).split('/')
    for i in raw_slash:
        raw1 = str(i).split('-')
        slash_token = []
        for j in range(0,len(raw1)):
            raw2 = str(raw1[j]).split('.')
            slash_token = slash_token + raw2
        dot_token_slash = dot_token_slash + raw1 + slash_token
    token = list(set(dot_token_slash)) 
    if 'com' in token:
        token.remove('com')
    return token

def predict_malware(features):
    # Load your trained classifier
    clf = joblib.load('Classifier/classifier.pkl')
    
    # Extracted features are in string format, convert them to a list of floats
    features_list = [int(x) for x in features.strip('[]').split(',')]
    answer= clf.predict([features_list])[0]

    return answer

def predict_url(s_url):
    file = "Classifier/url_model.pkl"
    with open(file, 'rb') as f1:  
        lgr = pickle.load(f1)
    f1.close()
    file = "Classifier/url_vector.pkl"
    with open(file, 'rb') as f2:  
        vectorizer = pickle.load(f2)
    f2.close()

    #predicting
    x = vectorizer.transform([s_url])
    y_predict = lgr.predict(x)

    return y_predict

def extract_features(file_path):
    # Run the PE extraction script with the provided file_path
    result = subprocess.run(["d:/malware-project-new/venv/Scripts/python.exe", "PE_extraxt.py", file_path], capture_output=True, text=True)
    return result.stdout.strip()

def extract_url(url):
    result= subprocess.run(["d:/malware-project-new/venv/Scripts/python.exe", "url_extraxt.py", url], capture_output=True, text=True)

    return result.stdout.strip()
def main():
    st.title("Malware Detection Website")
    pe_file_upload,url_checker=st.tabs(["File-Checker","URL-Checker"])
    with pe_file_upload:
        st.header("File-Checker")
        uploaded_file=st.file_uploader("Choose a file")
        if uploaded_file is not None:
            temp_dir = tempfile.mkdtemp()
            path = os.path.join(temp_dir, uploaded_file.name)
            with open(path, "wb") as f:
                f.write(uploaded_file.read())
            extracted_features = extract_features(path)
            print(type(extracted_features))
            print(extracted_features)
            st.subheader("Extracted Features:")
            st.text(extracted_features)

    #clf = joblib.load('Classifier/classifier.pkl')
    #features = pickle.loads(open(os.path.join('Classifier/features.pkl'),'rb').read())
    #predictor=clf.predict([extracted_features])
    #print(predictor)[0]
            prediction  = predict_malware(extracted_features)
            
    # Display the prediction result
            st.subheader("Prediction : ")
            st.text(['Legitimate', 'Malicious'][prediction] if prediction is not None else "Failed to predict.")


    with url_checker:
        st.header("URL Checker")
        url = st.text_input('URL', placeholder= "google.com")
        if st.button('Check'):
            url_check = extract_url(url)
            url_predict=predict_url(url_check)
            print(url_check)
            print(url_predict)
            if url_predict is not None and len(url_predict) > 0:
                prediction_label= url_predict[0]

                if prediction_label == 'good':
                    prediction_text = 'Safe'
                elif prediction_label == 'bad':
                    prediction_text = 'Malicious'
                else:
                    prediction_text = 'Failed to predict'
            else:
                prediction_text = 'Failed to predict'
            st.subheader("Prediction : ")
            st.text(prediction_text)
            

if __name__ == '__main__':
    main()

